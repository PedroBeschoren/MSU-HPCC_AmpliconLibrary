#!/bin/bash -login
 
#SBATCH --time=48:00:00					### limit of wall clock time - how long the job will run (same as -t)
#SBATCH --ntasks=2					### number of tasks - how many tasks (nodes) that you require (same as -n)
#SBATCH --cpus-per-task=20				### number of CPUs (or cores) per task (same as -c)
#SBATCH --mem=32G					### memory required per node - amount of memory (in bytes)
#SBATCH --job-name 01eeOTUj			### you can give your job a name for easier identification (same as -J)

cd ${SLURM_SUBMIT_DIR}

module load GCC/5.4.0-2.26  OpenMPI/1.10.3-CUDA
module load seqtk
module load vsearch/2.9.1

#mkdir clustered_OTU_ESV_maxee0.1/




# UNOISE3 ESV -zero radius OTUs
#/mnt/research/rdp/public/thirdParty/usearch11.0.667_i86linux64 -unoise3 dereplicated.1/uniques_sizein_ee01_cat58.fastq -tabbedout clustered_OTU_ESV_maxee0.1/unoise_zotus.txt -zotus clustered_OTU_ESV_maxee0.1/zotus.fasta
#/mnt/research/rdp/public/thirdParty/usearch11.0.667_i86linux64 -otutab filtered_maxee0.1/filtered.fastq -zotus clustered_OTU_ESV_maxee0.1/zotus.fasta -otutabout clustered_OTU_ESV_maxee0.1/otu_table_16S_UNOISE.txt

#UPARSE 97% OTUs # NOTE you might want to run -cluster_otus and -otutab in different sbatch orders if your file is immense 
/mnt/research/rdp/public/thirdParty/usearch11.0.667_i86linux64 -cluster_otus dereplicated.1/uniques_sizein_ee01_cat58.fastq -minsize 2 -otus clustered_OTU_ESV_maxee0.1/otus.fasta -uparseout clustered_OTU_ESV_maxee0.1/uparse_otus.txt -relabel OTU_ --threads 20
/mnt/research/rdp/public/thirdParty/usearch11.0.667_i86linux64 -otutab filtered_maxee0.1/filtered.fastq -otus clustered_OTU_ESV_maxee0.1/otus.fasta -otutabout clustered_OTU_ESV_maxee0.1/otu_table_16S_UPARSE.txt

#NOTE: if working with multiple contatenated libraries, filtered_maxee0.1/filtered.fastq refers to to a simple contcatenation of all fitered fastq of " 8_filtering_trimming.sb" from each library  